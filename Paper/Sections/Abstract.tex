% 100-200 words

\begin{abstract}

A robot control system was developed that could be taught tasks through reinforcement learning.  The system, nicknamed Fido, was designed to be universal regardless of the specific hardware inputs and outputs and does not need to be modified for the task at hand. In addition, Fido was built to learn with limited feedback, allowing humans to train Fido in a reasonable time frame. This was achieved through the training of artificial neural networks with a wire-fitted moving least squares interpolator following the $Q$-learning reinforcement algorithm and an action selection policy that utilizes a Boltzmann distribution of probability.  Initially robots of different drive systems were simulated with sensors to test functionality.  Next a small robot using the Intel Edison compute module was constructed for physical testing.  The robot was successfully trained to do a variety of tasks with limited feedback, such as staying put and driving to a point.  Fido successfully converged on these tasks in very few reward iterations while maintaining impressively low latency, demonstrating its potential as a comprehensive robot control system.

\end{abstract}